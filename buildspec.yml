version: 0.2

env:
  variables:
    CUDA_HOME: "/usr/local/cuda"

phases:
  install:
    runtime-versions:
      python: 3.10
    commands:
      - apt-get update && apt-get install -y cmake

  pre_build:
    commands:
      - echo "Installing CUDA Toolkit"
      - wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
      - dpkg -i cuda-keyring_1.0-1_all.deb
      - apt-get update
      - apt-get install -y cuda-toolkit-11-8
      - export PATH=/usr/local/cuda-11.8/bin${PATH:+:${PATH}}
      - export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
      - nvcc --version
      - nvidia-smi

  build:
    commands:
      - echo "Installing Python dependencies"
      - pip install --upgrade pip
      - pip uninstall -y torch
      - pip cache purge
      - pip install torch --index-url https://download.pytorch.org/whl/cu118
      - pip uninstall -y llama-cpp-python
      - pip cache remove llama_cpp_python
      - CMAKE_ARGS="-DLLAMA_CUDA=on" FORCE_CMAKE=1 pip install llama-cpp-python==0.2.75 --no-cache-dir
      - pip install instructlab --no-cache-dir
      
      - echo "Cloning repositories"
      - git clone https://github.com/nicklamb97/generated.git
      - git clone https://github.com/nicklamb97/instructlab-config.git
      
      - echo "Copying config file"
      - cp instructlab-config/config.yaml .

      - echo "Setting up CUDA environment"
      - export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu
      - ldconfig

      - echo "Validating ilab works"
      - ilab model --help

artifacts:
  files:
    - '**/*'

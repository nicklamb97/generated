version: 0.2

phases:
  install:
    runtime-versions:
      python: 3.10
    commands:
      - echo "Installing CUDA Toolkit"
      - apt-get update && apt-get install -y wget
      - wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
      - mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
      - wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb
      - dpkg -i cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb
      - cp /var/cuda-repo-ubuntu2204-11-8-local/cuda-*-keyring.gpg /usr/share/keyrings/
      - apt-get update
      - apt-get -y install cuda
      - export PATH=/usr/local/cuda-11.8/bin${PATH:+:${PATH}}
      - export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
      - echo "Upgrading pip and installing dependencies for GPU acceleration"
      - pip install --upgrade pip
      - pip uninstall -y torch
      - pip cache purge
      - pip install torch --index-url https://download.pytorch.org/whl/cu118
      - pip uninstall -y llama-cpp-python
      - pip cache remove llama_cpp_python
      - export CUDA_HOME=/usr/local/cuda-11.8
      - export CMAKE_ARGS="-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all"
      - FORCE_CMAKE=1 pip install llama-cpp-python==0.2.75 --no-cache-dir
      - pip install instructlab --no-cache-dir
      - pip install huggingface_hub
  pre_build:
    commands:
      - echo "Cloning repositories"
      - git clone https://github.com/nicklamb97/generated.git
      - git clone https://github.com/nicklamb97/instructlab-config.git
      - echo "Copying config file"
      - cp instructlab-config/config.yaml .
      - echo "Checking GPU acceleration support"
      - |
        python - <<EOF
        import llama_cpp
        is_supported = llama_cpp.llama_supports_gpu_offload()
        print("Is GPU acceleration supported: " + str(is_supported))
        EOF
  build:
    commands:
      - echo "Downloading pre-trained model"
      - ilab model download --repository=NickLamb/OpenROAD-7B-Instruct --filename=OpenROAD-7B-Instruct.Q4_K_M.gguf
      - echo "Training model"
      - ilab model train --num-epochs 20 --device=cuda
      - echo "Uploading to Hugging Face"
      - |
        python - <<EOF
        from huggingface_hub import login, upload_folder
        login(token="${HF_TOKEN}")
        upload_folder(
            folder_path="models",
            path_in_repo="",
            repo_id="NickLamb/OpenROAD-7B-Instruct",
            repo_type="model"
        )
        EOF

env:
  variables:
    HF_TOKEN: ${HF_TOKEN}

artifacts:
  files:
    - '**/*'
